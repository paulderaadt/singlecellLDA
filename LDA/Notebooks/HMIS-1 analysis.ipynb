{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration of CyTOF sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCR6</th>\n",
       "      <th>CD19</th>\n",
       "      <th>C-KIT</th>\n",
       "      <th>CD11b</th>\n",
       "      <th>CD4</th>\n",
       "      <th>CD8a</th>\n",
       "      <th>CD7</th>\n",
       "      <th>CD25</th>\n",
       "      <th>CD123</th>\n",
       "      <th>TCRgd</th>\n",
       "      <th>...</th>\n",
       "      <th>CD8b</th>\n",
       "      <th>CD27</th>\n",
       "      <th>IL-15Ra</th>\n",
       "      <th>CD45RA</th>\n",
       "      <th>CD3</th>\n",
       "      <th>CD28</th>\n",
       "      <th>CD38</th>\n",
       "      <th>NKp46</th>\n",
       "      <th>PD-1</th>\n",
       "      <th>CD56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.085600</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.74139</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.36620</td>\n",
       "      <td>4.44010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.18260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3079</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.30830</td>\n",
       "      <td>0.875990</td>\n",
       "      <td>1.45540</td>\n",
       "      <td>5.1563</td>\n",
       "      <td>1.780700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.89030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.10050</td>\n",
       "      <td>0.70986</td>\n",
       "      <td>3.43200</td>\n",
       "      <td>0.575670</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>2.16630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.18660</td>\n",
       "      <td>4.679200</td>\n",
       "      <td>2.43820</td>\n",
       "      <td>2.1834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.718080</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.02720</td>\n",
       "      <td>4.46690</td>\n",
       "      <td>1.78540</td>\n",
       "      <td>4.58310</td>\n",
       "      <td>1.251000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.95560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0206</td>\n",
       "      <td>4.1595</td>\n",
       "      <td>0.87585</td>\n",
       "      <td>3.67660</td>\n",
       "      <td>4.843400</td>\n",
       "      <td>2.51750</td>\n",
       "      <td>5.1084</td>\n",
       "      <td>0.360730</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.62200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.50629</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086891</td>\n",
       "      <td>2.00060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5498</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.96750</td>\n",
       "      <td>0.470450</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.5044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.55330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.51423</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.39030</td>\n",
       "      <td>5.61950</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.26040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3466</td>\n",
       "      <td>4.6891</td>\n",
       "      <td>0.54675</td>\n",
       "      <td>2.45160</td>\n",
       "      <td>0.055771</td>\n",
       "      <td>0.49921</td>\n",
       "      <td>4.9283</td>\n",
       "      <td>4.339900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.88430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.895450</td>\n",
       "      <td>0.52039</td>\n",
       "      <td>0.87272</td>\n",
       "      <td>4.63860</td>\n",
       "      <td>2.14740</td>\n",
       "      <td>2.46940</td>\n",
       "      <td>2.393000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.85497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.1459</td>\n",
       "      <td>0.49494</td>\n",
       "      <td>0.41278</td>\n",
       "      <td>3.770400</td>\n",
       "      <td>2.95100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.51320</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.49850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.21490</td>\n",
       "      <td>2.40460</td>\n",
       "      <td>0.79798</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.28000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.7208</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.79212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.79122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.57960</td>\n",
       "      <td>0.29069</td>\n",
       "      <td>4.08020</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.27990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4529</td>\n",
       "      <td>4.4697</td>\n",
       "      <td>2.49790</td>\n",
       "      <td>3.83380</td>\n",
       "      <td>4.024800</td>\n",
       "      <td>1.98380</td>\n",
       "      <td>2.9021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053175</td>\n",
       "      <td>0.21142</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.64890</td>\n",
       "      <td>1.16870</td>\n",
       "      <td>4.19110</td>\n",
       "      <td>0.796630</td>\n",
       "      <td>1.099400</td>\n",
       "      <td>0.71934</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2473</td>\n",
       "      <td>4.3725</td>\n",
       "      <td>2.71460</td>\n",
       "      <td>3.92080</td>\n",
       "      <td>5.332100</td>\n",
       "      <td>2.99210</td>\n",
       "      <td>3.1731</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.50133</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.09870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.44279</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.14192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.062000</td>\n",
       "      <td>1.65130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1142</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.55620</td>\n",
       "      <td>2.621100</td>\n",
       "      <td>0.66133</td>\n",
       "      <td>1.7915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CCR6      CD19    C-KIT    CD11b      CD4     CD8a      CD7      CD25  \\\n",
       "0  0.00000  1.085600  0.00000  0.74139  0.00000  3.36620  4.44010  0.000000   \n",
       "1  0.00000  0.000000  0.01100  0.00000  4.10050  0.70986  3.43200  0.575670   \n",
       "2  0.00000  0.718080  0.00000  1.02720  4.46690  1.78540  4.58310  1.251000   \n",
       "3  2.62200  0.000000  0.00000  0.00000  0.50629  0.00000  0.00000  0.000000   \n",
       "4  1.55330  0.000000  0.00000  0.51423  0.00000  3.39030  5.61950  0.017399   \n",
       "5  0.00000  0.895450  0.52039  0.87272  4.63860  2.14740  2.46940  2.393000   \n",
       "6  0.49850  0.000000  0.00000  4.21490  2.40460  0.79798  0.00000  0.000000   \n",
       "7  0.79122  0.000000  0.00000  0.00000  4.57960  0.29069  4.08020  0.022798   \n",
       "8  0.00000  0.053175  0.21142  0.00000  4.64890  1.16870  4.19110  0.796630   \n",
       "9  2.09870  0.000000  0.00000  0.44279  0.00000  0.00000  0.14192  0.000000   \n",
       "\n",
       "      CD123    TCRgd   ...       CD8b    CD27  IL-15Ra   CD45RA       CD3  \\\n",
       "0  0.000000  2.18260   ...     0.0000  1.3079  0.00000  4.30830  0.875990   \n",
       "1  0.006000  2.16630   ...     0.0000  4.2390  0.00000  3.18660  4.679200   \n",
       "2  0.000000  1.95560   ...     1.0206  4.1595  0.87585  3.67660  4.843400   \n",
       "3  0.086891  2.00060   ...     1.5498  0.0000  0.00000  3.96750  0.470450   \n",
       "4  0.000000  1.26040   ...     1.3466  4.6891  0.54675  2.45160  0.055771   \n",
       "5  0.000000  0.85497   ...     0.0000  3.1459  0.49494  0.41278  3.770400   \n",
       "6  0.060363  0.00000   ...     0.0000  0.0000  0.00000  2.28000  0.000000   \n",
       "7  0.000000  1.27990   ...     1.4529  4.4697  2.49790  3.83380  4.024800   \n",
       "8  1.099400  0.71934   ...     1.2473  4.3725  2.71460  3.92080  5.332100   \n",
       "9  1.062000  1.65130   ...     0.0000  1.1142  0.00000  4.55620  2.621100   \n",
       "\n",
       "      CD28    CD38     NKp46     PD-1     CD56  \n",
       "0  1.45540  5.1563  1.780700  0.00000  3.89030  \n",
       "1  2.43820  2.1834  0.000000  0.00000  0.83889  \n",
       "2  2.51750  5.1084  0.360730  0.00000  0.13717  \n",
       "3  0.00000  2.5044  0.000000  0.00000  0.00000  \n",
       "4  0.49921  4.9283  4.339900  0.00000  5.88430  \n",
       "5  2.95100  0.0000  0.000000  2.51320  0.00000  \n",
       "6  0.00000  4.7208  0.272800  0.00000  0.79212  \n",
       "7  1.98380  2.9021  0.000000  0.00000  0.00000  \n",
       "8  2.99210  3.1731  0.036992  0.50133  0.00000  \n",
       "9  0.66133  1.7915  0.000000  0.00000  0.00000  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"../Data/HMIS-1/Samples/Samples01_CeD.csv\", header=None)\n",
    "markers = ['CCR6','CD19','C-KIT','CD11b','CD4','CD8a','CD7','CD25','CD123','TCRgd','CD45',\n",
    "           'CRTH2','CD122','CCR7','CD14','CD11c','CD161','CD127','CD8b','CD27','IL-15Ra','CD45RA',\n",
    "           'CD3','CD28','CD38','NKp46','PD-1','CD56']\n",
    "sample.columns = markers\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare variables for data acquisition from CSV results\n",
    "labelfiles = os.listdir(\"../Data/HMIS-1/Labels/\")\n",
    "samplefiles = os.listdir(\"../Data/HMIS-1/Samples/\")\n",
    "labelfiles.sort()\n",
    "samplefiles.sort()\n",
    "F1list = []\n",
    "Acclist = []\n",
    "predictfiles = os.listdir(\"../Results/Predictions/HMIS-1 LDA/CV-sample\")\n",
    "predictfiles.sort()\n",
    "truedict = {}\n",
    "preddict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data acquisition from CSV results\n",
    "\n",
    "for i in range(len(samplefiles)):\n",
    "    #Calculate F1 & accuracy scores for each prediciton\n",
    "    true = pd.read_csv(\"../Data/HMIS-1/Labels/\" + labelfiles[i], header=None, engine='python').values.ravel()\n",
    "    predicted = pd.read_csv(\"../Results/Predictions/HMIS-1 LDA/CV-sample/\" + predictfiles[i], header=None, engine='python').values.ravel()\n",
    "    F1list.append(metrics.f1_score(list(true), list(predicted), average=None, labels=list(set(true))))\n",
    "    Acclist.append(metrics.accuracy_score(list(true), list(predicted)))\n",
    "    #Calculate counts of all original labels\n",
    "    unique, counts = np.unique(true, return_counts=True)\n",
    "    temp = dict(zip(unique, counts))\n",
    "    for celltype in temp:\n",
    "        try:\n",
    "            truedict[celltype] += temp[celltype]\n",
    "        except KeyError:\n",
    "            truedict[celltype] = temp[celltype]\n",
    "    #Calculate counts of all predicted labels\n",
    "    unique, counts = np.unique(predicted, return_counts=True)\n",
    "    temp = dict(zip(unique, counts))\n",
    "    for celltype in temp:\n",
    "        try:\n",
    "            preddict[celltype] += temp[celltype]\n",
    "        except KeyError:\n",
    "            preddict[celltype] = temp[celltype]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV-sample stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cell predictions made: 3553596\n",
      "Original number of true labels: 3553596\n"
     ]
    }
   ],
   "source": [
    "instancecount =0\n",
    "for key in preddict:\n",
    "    instancecount += truedict[key]\n",
    "print('Number of cell predictions made: %i' % instancecount)\n",
    "instancecount =0\n",
    "for key in preddict:\n",
    "    instancecount += truedict[key]\n",
    "print('Original number of true labels: %i' % instancecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf3aB/0X7ki7dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set width of bars\n",
    "barWidth = 0.25\n",
    "# set height of bars\n",
    "bars = [[dictionary[key] for key in dictionary] for dictionary in [truedict, preddict]]\n",
    "for x in range(len(bars)):\n",
    "    total = sum(bars[x])\n",
    "    for y in range(len(bars[x])):\n",
    "        bars[x][y] = bars[x][y] / total\n",
    "#set bar x coords\n",
    "r1 = np.arange(6)\n",
    "r2 = r1 + 0.25\n",
    "#plot bars & ticks\n",
    "plt.bar(r1, bars[0], color='green', width=barWidth, edgecolor='black', label='true')\n",
    "plt.bar(r2, bars[1], color='purple', width=barWidth, edgecolor='black', label='predicted')\n",
    "plt.xticks([r + barWidth for r in range(len(bars[0]))], ['B Cells', 'CD4 T', 'CD8 T', 'ILCs', 'Myeloid', 'Others'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMIS-1 CV-samples\n",
      "Accuracy mean: 98.52\n",
      "Accuracy std: 2.37\n",
      "F1 median: 0.97\n"
     ]
    }
   ],
   "source": [
    "F1median = np.median(np.sum(F1list,axis=0)/len(F1list))\n",
    "Accmean = np.mean(Acclist) * 100\n",
    "Accstd = np.std(Acclist) * 100\n",
    "print('HMIS-1 CV-samples')\n",
    "print('Accuracy mean: %s' % round(Accmean, 2))\n",
    "print('Accuracy std: %s' % round(Accstd, 2))\n",
    "print('F1 median: %s' % round(F1median, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV-cells stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all labels for 5-cold CV performance\n",
    "predictlabels = pd.DataFrame()\n",
    "truelabels = pd.DataFrame()\n",
    "\n",
    "for batch in range(1, 6):\n",
    "    predictlabels = predictlabels.append(pd.read_csv(\"../Results/Predictions/HMIS-1 LDA/CV-cells/\" + 'predict_batch_' + str(batch) +'.csv',\n",
    "                                          header=None, engine='python'))\n",
    "for filename in labelfiles:\n",
    "    truelabels = truelabels.append(pd.read_csv(\"../Data/HMIS-1/Labels/\" + filename, header=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracies and F1 scores for 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 710720  710721  710722 ... 3553593 3553594 3553595] [     0      1      2 ... 710717 710718 710719]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [710720, 35695]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7645b758f247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruelabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mF1list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mAcclist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [710720, 35695]"
     ]
    }
   ],
   "source": [
    "F1list  = []\n",
    "Acclist = []\n",
    "\n",
    "kfoldsplitter = KFold(n_splits=5)\n",
    "for train, test in kfoldsplitter.split(predictlabels):\n",
    "    print(train, test)\n",
    "    true = truelabels.iloc[test].values.ravel()\n",
    "    pred = predictlabels.iloc[test].values.ravel()\n",
    "    F1list.append(metrics.f1_score(true, predicted, average=None, labels=list(set(true))))\n",
    "    Acclist.append(metrics.accuracy_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1median = np.median(np.sum(F1list,axis=0)/len(F1list))\n",
    "Accmean = np.mean(Acclist) * 100\n",
    "Accstd = np.std(Acclist) * 100\n",
    "print('HMIS-1 CV-cells')\n",
    "print('Accuracy mean: %s' % round(Accmean, 2))\n",
    "print('Accuracy std: %s' % round(Accstd, 2))\n",
    "print('F1 median: %s' % round(F1median, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
